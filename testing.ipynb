{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "from src.datasets.BBBC039 import BBBC039\n",
    "\n",
    "train_transform = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((262.3408031194739), (220.18462229587527)),\n",
    "    ]\n",
    ")\n",
    "dataset = BBBC039(\"data\", subset=None, imgs_transform=train_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from typing import Callable, Final\n",
    "\n",
    "\n",
    "class BBBC039DataModule(pl.LightningDataModule):\n",
    "    normalisation_transform: Final[Callable] = tv.transforms.Compose(\n",
    "        [\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize(mean=(262.3408031194739), std=(220.18462229587527)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = \"data\",\n",
    "        batch_size: int = 4,\n",
    "        imgs_transform: Callable = normalisation_transform,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.batch_size = batch_size\n",
    "        self.imgs_transform = imgs_transform\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Download and preprocess\n",
    "        BBBC039(self.root, subset=None, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            # Model fitting with train and validation sets\n",
    "            self.bbc039_train = BBBC039(self.root, \"training\", self.imgs_transform)\n",
    "            self.bbc039_val = BBBC039(self.root, \"validation\", self.imgs_transform)\n",
    "        elif stage == \"test\":\n",
    "            # Model testing with the test set\n",
    "            self.bbc039_test = BBBC039(self.root, \"test\", self.imgs_transform)\n",
    "        elif stage == \"predict\":\n",
    "            # Model prediction uses the same test set\n",
    "            self.bbc039_predict = BBBC039(self.root, \"test\", self.imgs_transform)\n",
    "\n",
    "        def train_dataloader(self):\n",
    "            return DataLoader(self.bbc039_train, batch_size=self.batch_size)\n",
    "\n",
    "        def val_dataloader(self):\n",
    "            return DataLoader(self.bbc039_val, batch_size=self.batch_size)\n",
    "\n",
    "        def test_dataloader(self):\n",
    "            return DataLoader(self.bbc039_test, batch_size=self.batch_size)\n",
    "\n",
    "        def predict_dataloader(self):\n",
    "            return DataLoader(self.bbc039_predict, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = BBBC039DataModule(root=\"./data\", batch_size=4)\n",
    "x.setup(\"fit\")\n",
    "tv.transforms.ToPILImage()(x.bbc039_train[0][1])\n",
    "x.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(x)[:,:,:3])\n",
    "np.unique(np.array(x)[:, :, 0])\n",
    "plt.plot(np.array(x)[:, :, :1])\n",
    "# np.array(x)[:, :, :1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.open(\"data/masks/IXMtest_A02_s1_w1051DAA7C-7042-435F-99F0-1E847D9B42CB.png\")\n",
    "# plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(m[1] * 255)\n",
    "np.unique(m.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for x in range(10):\n",
    "plt.imshow(i[0])\n",
    "plt.show()\n",
    "plt.imshow(m[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# tv.transforms.Normalize((262.3408031194739), (220.18462229587527))(\n",
    "torch.double(np.array(imgs2, dtype=np.int16))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0]\n",
    "\n",
    "imgs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.open(\"data/images/IXMtest_A09_s1_w1CE70AD49-290D-4312-82E6-CDC717F32637.tif\")\n",
    "# plt.imshow(np.array(x))\n",
    "plt.imshow(\n",
    "    np.array(\n",
    "        tv.transforms.ToPILImage()(\n",
    "            tv.transforms.Normalize((262.3408031194739), (220.18462229587527))(\n",
    "                tv.transforms.ToTensor()(np.array(x, dtype=np.float_))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP3419",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
