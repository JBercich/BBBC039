{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBBC039 Segmentation Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "# run = api.run(f\"joshbercich/BBBC039-Segmentation/jrhkyfjn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = api.run(\"joshbercich/BBBC039-Segmentation/qjikuwvn\")\n",
    "# run.config[\"rand_augment\"] = False\n",
    "# run.config[\"rand_augment_n\"] = None\n",
    "# run.config[\"rand_augment_m\"] = None\n",
    "# run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torchvision\n",
    "from lightning.pytorch import LightningModule, Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import (\n",
    "    Dice,\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MultilabelCoverageError,\n",
    "    MulticlassJaccardIndex,\n",
    ")\n",
    "from torchvision.transforms import InterpolationMode, Resize\n",
    "\n",
    "import wandb\n",
    "from dataset import BBBC039Segmentation\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "\n",
    "class UNet(LightningModule):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 1e-4,\n",
    "        in_channels: int = 3,\n",
    "        out_channels: int = 3,\n",
    "        init_features: int = 32,\n",
    "        pretrained: bool = False,\n",
    "        rand_augment: bool = False,\n",
    "        rand_augment_n: int = None,\n",
    "        rand_augment_m: float = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rand_augment = rand_augment\n",
    "        self.rand_augment_n = rand_augment_n\n",
    "        self.rand_augment_m = rand_augment_m\n",
    "        if self.rand_augment:\n",
    "            assert self.rand_augment_n is not None and self.rand_augment_m is not None\n",
    "\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Construct the model with the given parameters\n",
    "        torch.hub._validate_not_a_forked_repo = lambda a, b, c: True\n",
    "        self.net = torch.hub.load(\n",
    "            \"mateuszbuda/brain-segmentation-pytorch\",\n",
    "            \"unet\",\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            init_features=init_features,\n",
    "            pretrained=pretrained,\n",
    "        )\n",
    "\n",
    "        # Set the model loss function\n",
    "        self.loss = torch.nn.functional.cross_entropy\n",
    "\n",
    "        # Calculate the model number of hyperparameters\n",
    "        self.num_parameters = sum(layer.numel() for layer in self.net.parameters())\n",
    "        self.log(\"num_parameters\", self.num_parameters, logger=True)\n",
    "\n",
    "        # Define modular metrics\n",
    "        self.train_f1 = MulticlassF1Score(num_classes=3)\n",
    "        self.train_coverage = MultilabelCoverageError(num_labels=3)\n",
    "        self.train_accuracy = MulticlassAccuracy(num_classes=3)\n",
    "        self.train_dice = Dice(num_classes=3)\n",
    "        self.val_f1 = MulticlassF1Score(num_classes=3)\n",
    "        self.val_coverage = MultilabelCoverageError(num_labels=3)\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=3)\n",
    "        self.val_dice = Dice(num_classes=3)\n",
    "        self.test_f1 = MulticlassF1Score(num_classes=3)\n",
    "        self.test_f1_binary = MulticlassF1Score(num_classes=3, ignore_index=2)\n",
    "        self.test_coverage = MultilabelCoverageError(num_labels=3)\n",
    "        self.test_coverage_binary = MultilabelCoverageError(\n",
    "            num_labels=3, ignore_index=2\n",
    "        )\n",
    "        self.test_accuracy = MulticlassAccuracy(num_classes=3)\n",
    "        self.test_accuracy_binary = MulticlassAccuracy(num_classes=3, ignore_index=2)\n",
    "        self.test_dice = Dice(num_classes=3)\n",
    "        self.test_dice_binary = Dice(num_classes=3, ignore_index=2)\n",
    "        self.test_jid = MulticlassJaccardIndex(num_classes=3)\n",
    "        self.test_jid_binary = MulticlassJaccardIndex(num_classes=3, ignore_index=2)\n",
    "\n",
    "        # Shorthand for logger options\n",
    "        self.train_log_opts = {\"on_step\": True, \"on_epoch\": True, \"logger\": True}\n",
    "        self.val_log_opts = {\"on_step\": False, \"on_epoch\": True, \"logger\": True}\n",
    "        self.test_log_opts = {\"on_step\": False, \"on_epoch\": True, \"logger\": True}\n",
    "\n",
    "        # Save the hyperparameters for this model\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch: tuple, batch_idx: int):\n",
    "        # Load and inference\n",
    "        images, labels = batch\n",
    "        output = self.net(images)\n",
    "        pred, labs = output.argmax(1), labels.int().argmax(1)\n",
    "        loss = self.loss(output, labels)\n",
    "\n",
    "        # Update metrics\n",
    "        self.train_f1(pred, labs)\n",
    "        self.train_coverage(output, labels)\n",
    "        self.train_accuracy(pred, labs)\n",
    "        self.train_dice(pred, labs)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, **self.train_log_opts)\n",
    "        self.log(\"train_f1\", self.train_f1, prog_bar=True, **self.train_log_opts)\n",
    "        self.log(\"train_coverage\", self.train_coverage, **self.train_log_opts)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy, **self.train_log_opts)\n",
    "        self.log(\"train_dice\", self.train_dice, **self.train_log_opts)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple, batch_idx: int):\n",
    "        # Load and inference\n",
    "        images, labels = batch\n",
    "        output = self.net(images)\n",
    "        pred, labs = output.argmax(1), labels.int().argmax(1)\n",
    "        loss = self.loss(output, labels)\n",
    "\n",
    "        # Update metrics\n",
    "        self.val_f1(pred, labs)\n",
    "        self.val_coverage(output, labels)\n",
    "        self.val_accuracy(pred, labs)\n",
    "        self.val_dice(pred, labs)\n",
    "        self.log(\"val_loss\", loss, **self.val_log_opts)\n",
    "        self.log(\"val_f1\", self.val_f1, prog_bar=True, **self.val_log_opts)\n",
    "        self.log(\"val_coverage\", self.val_coverage, **self.val_log_opts)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy, **self.val_log_opts)\n",
    "        self.log(\"val_dice\", self.val_dice, **self.val_log_opts)\n",
    "        return (output, labels)\n",
    "\n",
    "    def on_validation_batch_end(self, output, batch: tuple, batch_idx: int):\n",
    "        if batch_idx == 0:\n",
    "            pred, labs = output\n",
    "            self.logger.log_image(\"prediction\", [wandb.Image(pred[0])])\n",
    "            self.logger.log_image(\"true_label\", [wandb.Image(labs[0])])\n",
    "\n",
    "    def test_step(self, batch: tuple, batch_idx: int):\n",
    "        # Load and inference\n",
    "        images, labels = batch\n",
    "        output = self.net(images)\n",
    "        pred, labs = output.argmax(1), labels.int().argmax(1)\n",
    "        loss = self.loss(output, labels)\n",
    "\n",
    "        # Update metrics\n",
    "        self.test_f1(pred, labs)\n",
    "        self.test_coverage(output, labels)\n",
    "        self.test_accuracy(pred, labs)\n",
    "        self.test_dice(pred, labs)\n",
    "        self.test_f1_binary(pred, labs)\n",
    "        self.test_coverage_binary(output, labels)\n",
    "        self.test_accuracy_binary(pred, labs)\n",
    "        self.test_dice_binary(pred, labs)\n",
    "        self.test_jid(pred, labs)\n",
    "        self.test_jid_binary(pred, labs)\n",
    "        self.log(\"test_loss\", loss, **self.test_log_opts)\n",
    "        self.log(\"test_f1\", self.test_f1, **self.test_log_opts)\n",
    "        self.log(\"test_f1_binary\", self.test_f1_binary, **self.test_log_opts)\n",
    "        self.log(\"test_coverage\", self.test_coverage, **self.test_log_opts)\n",
    "        self.log(\n",
    "            \"test_coverage_binary\", self.test_coverage_binary, **self.test_log_opts\n",
    "        )\n",
    "        self.log(\"test_accuracy\", self.test_accuracy, **self.test_log_opts)\n",
    "        self.log(\n",
    "            \"test_accuracy_binary\", self.test_accuracy_binary, **self.test_log_opts\n",
    "        )\n",
    "        self.log(\"test_dice\", self.test_dice, **self.test_log_opts)\n",
    "        self.log(\"test_dice_binary\", self.test_dice_binary, **self.test_log_opts)\n",
    "        self.log(\"test_jid\", self.test_jid, **self.test_log_opts)\n",
    "        self.log(\"test_jid_binary\", self.test_jid_binary, **self.test_log_opts)\n",
    "\n",
    "    def predict_step(self, batch: tuple, batch_idx: int):\n",
    "        return self.net(batch[0]).argmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimiser = torch.optim.Adam(self.net.parameters(), lr=self.learning_rate)\n",
    "        return optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class ModelEvaluation:\n",
    "    @staticmethod\n",
    "    def collect_checkpoint_files() -> list[str]:\n",
    "        checkpoint_files = []\n",
    "        for root, dirs, files in os.walk(\".\"):\n",
    "            for file in files:\n",
    "                if file.endswith(\".ckpt\"):\n",
    "                    checkpoint_files.append(os.path.join(root, file))\n",
    "        return checkpoint_files\n",
    "\n",
    "\n",
    "model = UNet.load_from_checkpoint(ModelEvaluation.collect_checkpoint_files()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = Resize((256, 256), InterpolationMode.NEAREST)\n",
    "# test_dataset = BBBC039Segmentation(\"../datasets/\", subset=\"test\", transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, shuffle=False, batch_size=8)\n",
    "# trainer = Trainer()\n",
    "\n",
    "# for i, checkpoint in enumerate(ModelEvaluation.collect_checkpoint_files()):\n",
    "#     if i < 5:\n",
    "#         continue\n",
    "#     run_title = checkpoint.split(os.sep)[-3]\n",
    "#     run = api.run(f\"joshbercich/BBBC039-Segmentation/{run_title}\")\n",
    "#     model = UNet.load_from_checkpoint(checkpoint)\n",
    "#     result = trainer.test(model, test_loader)[0]\n",
    "#     print(run.name, result)\n",
    "#     for k, v in result.items():\n",
    "#         run.summary[k] = v\n",
    "#     run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import SAM\n",
    "\n",
    "# Load the model\n",
    "model = SAM(\"mobile_sam.pt\")\n",
    "\n",
    "# Predict a segment based on a point prompt\n",
    "# model.predict(\"ultralytics/assets/zidane.jpg\", points=[900, 370], labels=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BBBC039Segmentation(\"../datasets/\")\n",
    "x, y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLOv8n model\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "# results = model.train(data='coco8.yaml', epochs=100, imgsz=640)\n",
    "\n",
    "z = model(y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ToPILImage()(y)\n",
    "label = np.array(label)\n",
    "label[:, :, 0] = 0\n",
    "plt.imshow(label.sum(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn_resnet50_fpn_v2(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchmetrics.classification as metrics\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup default plotting environment\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "mpl.rcParams[\"legend.frameon\"] = True\n",
    "mpl.rcParams[\"axes.grid\"] = True\n",
    "mpl.rcParams[\"grid.alpha\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(\"results-loss.csv\")\n",
    "res = res.melt(id_vars=[\"epoch\"], var_name=\"Model\", value_name=\"Loss\")\n",
    "res = res[~res[\"Model\"].str.contains(\"__\")]\n",
    "res[\"Model\"] = res[\"Model\"].apply(lambda x: x.split(\"_unet\")[0])\n",
    "res[\"Ablation\"] = res[\"Model\"].apply(\n",
    "    lambda x: \"RandAugment\" if \"rand\" in x else \"Baseline\"\n",
    ")\n",
    "res[\"Learning Rate\"] = res[\"Model\"].apply(lambda x: 0.001 if \"fast\" in x else 0.0001)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(\"test-summary.csv\")\n",
    "res[\"Name\"] = res[\"Name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "res[\"F1\"] = (\n",
    "    (res[\"test_f1\"] * 100).round(2).astype(str)\n",
    "    + \"/\"\n",
    "    + (res[\"test_f1_binary\"] * 100).round(2).astype(str)\n",
    ")\n",
    "res[\"JID\"] = (\n",
    "    (res[\"test_jid\"] * 100).round(2).astype(str)\n",
    "    + \"/\"\n",
    "    + (res[\"test_jid_binary\"] * 100).round(2).astype(str)\n",
    ")\n",
    "res[\"Dice\"] = (\n",
    "    (res[\"test_dice\"] * 100).round(2).astype(str)\n",
    "    + \"/\"\n",
    "    + (res[\"test_dice_binary\"] * 100).round(2).astype(str)\n",
    ")\n",
    "res[\"Accuracy\"] = (\n",
    "    (res[\"test_accuracy\"] * 100).round(2).astype(str)\n",
    "    + \"/\"\n",
    "    + (res[\"test_accuracy_binary\"] * 100).round(2).astype(str)\n",
    ")\n",
    "# res[\"CovErr\"] = (\n",
    "#     (res[\"test_coverage\"]).round(2).astype(str)\n",
    "#     + \"/\"\n",
    "#     + (res[\"test_coverage_binary\"]).round(2).astype(str)\n",
    "# )\n",
    "res[\"rand_augment_n\"] = res[\"rand_augment_n\"].astype(str)\n",
    "res = res[\n",
    "    [\n",
    "        \"Name\",\n",
    "        \"init_features\",\n",
    "        \"learning_rate\",\n",
    "        \"rand_augment_n\",\n",
    "        \"rand_augment_m\",\n",
    "        # \"CovErr\",\n",
    "        \"Accuracy\",\n",
    "        \"Dice\",\n",
    "        \"JID\",\n",
    "        \"F1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(\n",
    "    (\n",
    "        res.sort_values(\n",
    "            [\n",
    "                \"rand_augment_n\",\n",
    "                \"rand_augment_m\",\n",
    "                \"init_features\",\n",
    "                \"learning_rate\",\n",
    "            ]\n",
    "        )\n",
    "    ).to_latex(index=False, na_rep=\"-\", float_format=\"{:0.2f}\".format)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP3419",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
