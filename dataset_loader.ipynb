{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision as tv\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from src.BBBC039.datamodule import BBBC039DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize(mean=(262.3408031194739), std=(220.18462229587527)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = BBBC039Dataset(\"data\", subset=\"training\", img_transform=img_transform)\n",
    "val_dataset = BBBC039Dataset(\"data\", subset=\"validation\", img_transform=img_transform)\n",
    "test_dataset = BBBC039Dataset(\"data\", subset=\"test\", img_transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = None\n",
    "optimiser = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running a model with wandb logging\n",
    "- Crossing over to lighting\n",
    "- Setting up test.py\n",
    "- setting up visualisations\n",
    "- writing up report sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    \"mateuszbuda/brain-segmentation-pytorch\",\n",
    "    \"unet\",\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    init_features=32,\n",
    "    pretrained=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision as tv\n",
    "\n",
    "for i in range(5):\n",
    "    image, mask = dataset[i]\n",
    "    _, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "    ax1.imshow(np.array(tv.transforms.ToPI`LImage()(image)), cmap=\"gray\")\n",
    "    ax2.imshow(np.array(tv.transforms.ToPILImage()(mask)), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = x[:, :, 0]\n",
    "annot = skimage.morphology.label(annot)\n",
    "\n",
    "# filter small objects, e.g. micronulcei\n",
    "annot = skimage.morphology.remove_small_objects(annot, min_size=25)\n",
    "\n",
    "# find boundaries\n",
    "boundaries = skimage.segmentation.find_boundaries(annot)\n",
    "\n",
    "for k in range(2, 2, 2):\n",
    "    boundaries = skimage.morphology.binary_dilation(boundaries)\n",
    "\n",
    "# BINARY LABEL\n",
    "\n",
    "# prepare buffer for binary label\n",
    "label_binary = np.zeros((annot.shape + (3,)))\n",
    "\n",
    "# write binary label\n",
    "label_binary[(annot == 0) & (boundaries == 0), 0] = 1\n",
    "label_binary[(annot != 0) & (boundaries == 0), 1] = 1\n",
    "label_binary[boundaries == 1, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binary.astype(np.uint8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision as tv\n",
    "# import torch\n",
    "# plt.imshow(tv.transforms.ToPILImage()\n",
    "# (\n",
    "#     tv.transforms.AutoAugment()(torch.Tensor((label_binary*).astype(np.uint8).reshape(3, 520, 696)).type(torch.uint8))\n",
    "#     )\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(boundaries)\n",
    "# plt.show()\n",
    "# plt.imshow(label_binary)\n",
    "# plt.show()\n",
    "# np.unique(label_binary[None,None,:], axis=2)\n",
    "label_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[:, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(skimage.morphology.label(x[:, :, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[:, :, 0] >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "from enum import StrEnum, auto, unique\n",
    "from pathlib import Path\n",
    "from typing import Callable, TypeAlias, Final, final\n",
    "\n",
    "import math\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "_IDArray: TypeAlias = npt.NDArray[np.unicode_]\n",
    "_ImageArray: TypeAlias = npt.NDArray[np.float_]\n",
    "\n",
    "\n",
    "class BBBC039Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    BBBC039 dataset.\n",
    "\n",
    "    Segmentation mask dataset for U2OS cell nuclei obtained through fluorescence\n",
    "    microscopy. Contains approximately 23,000 individually manually annotated nuclei.\n",
    "    TIF image and PNG mask files are 520x696 pixels.\n",
    "\n",
    "    Sourced from: https://bbbc.broadinstitute.org/BBBC039\n",
    "        Caicedo et al. 2018, available from the Broad Bioimage Benchmark Collection\n",
    "        [Ljosa et al., Nature Methods, 2012]\n",
    "\n",
    "    The dataset is made available across 3 archives consisting of image, mask and meta\n",
    "    directories which are all required when loading the dataset. Each archive should be\n",
    "    extracted and placed in a root directory. The minimal directory layout requirement\n",
    "    is described as follows:\n",
    "\n",
    "        ```\n",
    "        <root directory>\n",
    "        ├── images\n",
    "        │   ├── ...\n",
    "        ├── masks\n",
    "        │   ├── ...\n",
    "        └── metadata\n",
    "            ├── test.txt\n",
    "            ├── training.txt\n",
    "            └── validation.txt\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    # Dataset source url prefix\n",
    "    SOURCE_URL: Final[str] = \"https://data.broadinstitute.org/bbbc/BBBC039/\"\n",
    "    NUCLEI_MINIMUM_SIZE: Final[int] = 25\n",
    "    NUCLEI_BORDER_WIDTH: Final[int] = 2\n",
    "\n",
    "    # Required file extensions\n",
    "    @final\n",
    "    @unique\n",
    "    class FileExtension(StrEnum):\n",
    "        Images = \".tif\"\n",
    "        Masks = \".png\"\n",
    "\n",
    "    # Required subdirectories\n",
    "    @final\n",
    "    @unique\n",
    "    class Subdirectory(StrEnum):\n",
    "        Images = auto()\n",
    "        Masks = auto()\n",
    "        Metadata = auto()\n",
    "\n",
    "    # Required subsets\n",
    "    @final\n",
    "    @unique\n",
    "    class Subset(StrEnum):\n",
    "        Training = auto()\n",
    "        Validation = auto()\n",
    "        Test = auto()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        subset: str = Subset.Training.value,\n",
    "        img_transform: Callable = None,\n",
    "        msk_transform: Callable = None,\n",
    "        download_dataset: bool = False,\n",
    "        force: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Resolve dataset root directory\n",
    "        self.root: Path = Path(root).resolve(strict=True)\n",
    "\n",
    "        # Download dataset if requested\n",
    "        if download_dataset:\n",
    "            self._download_dataset(root, force=force)\n",
    "\n",
    "        # Resolve required dataset directories\n",
    "        imgs_dir: Path = (self.root / self.Subdirectory.Images.value).resolve(\n",
    "            strict=True\n",
    "        )\n",
    "        msks_dir: Path = (self.root / self.Subdirectory.Masks.value).resolve(\n",
    "            strict=True\n",
    "        )\n",
    "        metadata_dir: Path = (self.root / self.Subdirectory.Metadata.value).resolve(\n",
    "            strict=True\n",
    "        )\n",
    "\n",
    "        # Extract subset ids\n",
    "        subsets: list[str] = [s.value for s in self.Subset]\n",
    "        subset_id_file: Path = metadata_dir / f\"{subset}.txt\"\n",
    "        match subset:\n",
    "            case None:  # Entire dataset\n",
    "                self.imgs_ids = [imgs_dir / i for i in imgs_dir if i.is_file()]\n",
    "                self.msks_ids = [msks_dir / i for i in msks_dir if i.is_file()]\n",
    "            case subset if subset in subsets:  # Dataset subset\n",
    "                self.imgs_ids, self.msks_ids = self._read_subset(subset_id_file)\n",
    "                self.imgs_ids = [imgs_dir / i for i in self.imgs_ids]\n",
    "                self.msks_ids = [msks_dir / i for i in self.msks_ids]\n",
    "            case _:\n",
    "                raise ValueError(f\"dataset subset '{subset}' is invalid -> {subsets}\")\n",
    "\n",
    "        # Define additional transformations\n",
    "        self.img_transform = img_transform\n",
    "        self.msk_transform = msk_transform\n",
    "\n",
    "        # Preprocess the dataset masks\n",
    "        self._preprocess_masks()\n",
    "\n",
    "    def _download_dataset(self, directory: Path, force: bool = False):\n",
    "        \"\"\"\n",
    "        Download the BBBC039 dataset.\n",
    "\n",
    "        Args:\n",
    "            directory (Path): Directory for the location of the downloaded dataset.\n",
    "            force (bool, optional): Overwrite any existing files. Defaults to False.\n",
    "        \"\"\"\n",
    "        # Prepare each required dataset archive\n",
    "        archives: list[str] = [f\"{i.value}.zip\" for i in self.Subdirectory]\n",
    "        for archive in archives:\n",
    "            # Download archive\n",
    "            self._download_file(self.SOURCE_URL + archive, directory / archive, force)\n",
    "            # Extract archive\n",
    "            if not force:\n",
    "                with zipfile.ZipFile(directory / archive, \"r\") as archive:\n",
    "                    archive.extractall(directory)\n",
    "\n",
    "    def _download_file(self, url: str, filepath: Path, force: bool = False):\n",
    "        \"\"\"\n",
    "        Download utility function.\n",
    "\n",
    "        Args:\n",
    "            url (str): URL for the download file.\n",
    "            filepath (Path): Filepath to write the output file.\n",
    "            force (bool, optional): Overwrite any existing file. Defaults to False.\n",
    "        \"\"\"\n",
    "        # Relative path used for concise stdout\n",
    "        relpath: Path = Path(filepath).relative_to(Path().absolute())\n",
    "        # Skip download if possible\n",
    "        if relpath.exists() and not force:\n",
    "            print(\"{:>20}: already downloaded (not forced)\".format(str(relpath)))\n",
    "            return\n",
    "        # Stream response for the given chunk size\n",
    "        chunk_size: int = 1024\n",
    "        response: requests.models.Response = requests.get(url, stream=True)\n",
    "        # Write response stream to file\n",
    "        with open(relpath, \"wb\") as write_file:\n",
    "            for chunk in tqdm(\n",
    "                response.iter_content(chunk_size=chunk_size),\n",
    "                \"{:>20}\".format(str(relpath)),\n",
    "                unit=\"B\",\n",
    "                total=math.ceil(int(response.headers[\"Content-Length\"]) / chunk_size),\n",
    "                unit_scale=True,\n",
    "                unit_divisor=chunk_size,\n",
    "            ):\n",
    "                write_file.write(chunk)\n",
    "\n",
    "    def _read_subset(self, filepath: Path) -> tuple[_IDArray, _IDArray]:\n",
    "        \"\"\"\n",
    "        Extract a specific BBBC039 dataset subset of image and mask ids.\n",
    "\n",
    "        Args:\n",
    "            filepath (Path): Path to metadata id split file.\n",
    "\n",
    "        Returns:\n",
    "            tuple[_IDArray, _IDArray]: Image and mask id arrays.\n",
    "        \"\"\"\n",
    "        # File ids are mask filepaths, and image ids replace the file extension\n",
    "        with open(filepath, \"r\") as split:\n",
    "            masks_ids: list[str] = split.read().splitlines()\n",
    "            image_ids: list[str] = [\n",
    "                mask_id.replace(self.FileExtension.Masks, self.FileExtension.Images)\n",
    "                for mask_id in masks_ids\n",
    "            ]\n",
    "        # Return the ids as numpy arrays for faster runtime\n",
    "        return np.array(image_ids), np.array(masks_ids)\n",
    "\n",
    "    def _preprocess_masks(self):\n",
    "        \"\"\"\n",
    "        Preprocess masks to have the correct segmentation classes. Defined classes are\n",
    "        specified for the background, nuclei and boundaries. These new images are saved\n",
    "        to the 'masks_preprocessed' directory and the msks_ids are updated.\n",
    "\n",
    "        Adapted from (CarpenterLab, 2018): https://github.com/carpenterlab/unet4nuclei\n",
    "        \"\"\"\n",
    "\n",
    "        # Define the new mask directory\n",
    "        msks_dir_processed: Path = self.root / \"masks_preprocessed\"\n",
    "        msks_dir_processed.mkdir(exist_ok=True)\n",
    "\n",
    "        # Process each file with a progress bar\n",
    "        for mask_filepath in tqdm(\n",
    "            self.msks_ids,\n",
    "            total=len(self.msks_ids),\n",
    "            desc=\"Preprocessing masks\",\n",
    "            unit=\"img\",\n",
    "        ):\n",
    "            # Define the masks filepath and skip if it exists\n",
    "            new_mask_filepath: Path = msks_dir_processed / mask_filepath.name\n",
    "            if new_mask_filepath.exists():\n",
    "                continue\n",
    "\n",
    "            # Read the mask file and cut off extra channels and alpha\n",
    "            mask: _ImageArray = np.array(Image.open(mask_filepath))\n",
    "            mask = mask[:, :, 0]\n",
    "            # Label all individual nuclei and remove smaller ones\n",
    "            mask = skimage.morphology.label(mask)\n",
    "            mask = skimage.morphology.remove_small_objects(\n",
    "                mask, min_size=self.NUCLEI_MINIMUM_SIZE\n",
    "            )\n",
    "            # Extract nuclei boundaries\n",
    "            mask_boundaries: _ImageArray = skimage.segmentation.find_boundaries(mask)\n",
    "            for _ in range(2, self.NUCLEI_BORDER_WIDTH, 2):\n",
    "                mask_boundaries = skimage.morphology.binary_dilation(mask_boundaries)\n",
    "            # Create the mask channels (background, nuclei, boundary)\n",
    "            mask_label: _ImageArray = np.zeros(mask.shape + (3,))\n",
    "            mask_label[(mask == 0) & (mask_boundaries == 0), 0] = 1\n",
    "            mask_label[(mask != 0) & (mask_boundaries == 0), 1] = 1\n",
    "            mask_label[mask_boundaries == 1, 2] = 1\n",
    "\n",
    "            # Save the new image\n",
    "            Image.fromarray(mask_label.astype(np.uint8)).save(new_mask_filepath)\n",
    "\n",
    "        # Update the masks lookup dir\n",
    "        self.msks_ids = [msks_dir_processed / path.name for path in self.msks_ids]\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Read into memory and transform an image and mask pair.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the image/mask pair to load and transform.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: Loaded and transformed image and mask.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load image and mask, convert to float for performing any further transforms\n",
    "        img: _ImageArray = np.array(Image.open(self.imgs_ids[index]), dtype=np.float_)\n",
    "        msk: _ImageArray = np.array(Image.open(self.msks_ids[index]), dtype=np.float_)\n",
    "\n",
    "        # Apply transformations and coerce image and mask into tensors\n",
    "        img = self.img_transform(img) if self.img_transform else img\n",
    "        img = img if isinstance(img, torch.Tensor) else tv.transforms.ToTensor()(img)\n",
    "        msk = self.msk_transform(msk) if self.msk_transform else msk\n",
    "        msk = msk if isinstance(msk, torch.Tensor) else tv.transforms.ToTensor()(msk)\n",
    "        return img, msk\n",
    "\n",
    "    def __len__(self):\n",
    "        # Dunder required for torch dataloaders\n",
    "        return len(self.imgs_ids)\n",
    "\n",
    "    def extract_to_numpy(self) -> tuple[_ImageArray, _ImageArray]:\n",
    "        \"\"\"\n",
    "        Convert the image and masks of the dataset to a numpy arrays with any applied\n",
    "        transformations. This allows for easy loading of the dataset into a simple numpy\n",
    "        format for any testing or other exploratory analyses.\n",
    "\n",
    "        Returns:\n",
    "            tuple[ImageArray, ImageArray]: Transformed image and mask numpy arrays.\n",
    "        \"\"\"\n",
    "        loaded_imgs = []\n",
    "        loaded_msks = []\n",
    "        for img, msk in self:\n",
    "            # Load and transform the image and masks to numpy arrays\n",
    "            loaded_imgs.append(np.array(tv.transforms.ToPILImage()(img)))\n",
    "            loaded_msks.append(np.array(tv.transforms.ToPILImage()(msk)))\n",
    "        # Convert the final lists to arrays\n",
    "        return np.array(loaded_imgs), np.array(loaded_msks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBBC039Dataset(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i * 255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP3419",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
